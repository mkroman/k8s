# Overrides for the magistr variant of this deployment.

irc:
  nick: anhero
  # The hostname or IP address of the IRC server.
  host: irc.rwx.im
  # The port number of the IRC server.
  port: 6667
  # Use a secure connection.
  tls: true
  # List of channels to join when initially connected.
  channels:
  - "#uplink"
  # List of nicknames to ignore messages from.
  ignored_nicks: ["meta", "chad*", "zeta*", "zet4", "anhero*", "moss*"]
  message_max_length: 4094

# Configuration for the GPT completion requests.
# Reference: https://beta.openai.com/docs/api-reference/completions
llm:
  provider: openai

  base_url: "https://api.perplexity.ai"

  # The identifier of the model to use for completions.
  model: r1-1776
  seed: 1337

  # What sampling temperature to use, between 0 and 2. Higher values like 0.8
  # will make the output more random, while lower values like 0.2 will make it
  # more focused and deterministic.
  # temperature: 1

  # The maximum number of tokens to generate in the chat completion.
  max_tokens: 32768

  # The reasoning method of the model. This controls how thoughts and answers
  # are extracted from the API response.
  #
  # Options:
  # * `think-answer-tags` - response is formatted with <think></think> and
  #    <answer></answer> tags and are extracted.
  # * `none` or false - response is preserved as is.
  reasoning_method: think-answer-tags

  # An alternative to sampling with temperature, called nucleus sampling, where
  # the model considers the results of the tokens with top_p probability mass.
  # So 0.1 means only the tokens comprising the top 10% probability mass are
  # considered.
  #
  # It's recommended to use this or `temperature`, but not both.
  # top_p: 1

  # Number between -2.0 and 2.0. Positive values penalize new tokens based on
  # whether they appear in the text so far, increasing the model's likelihood to
  # talk about new topics.
  # presence_penalty: 0.0

  # Number between -2.0 and 2.0. Positive values penalize new tokens based on
  # their existing frequency in the text so far, decreasing the model's
  # likelihood to repeat the same line verbatim.
  # frequency_penalty: 0.5

  # List of messages used for instructing GPT.
  #
  # Each message has `content` which will be templated with Mustache.
  #
  # Available variables:
  # `message` - The message a user sent to the bot (not including the bot nick)
  # `rawMessage` - The message a user sent to the bot, including the bot nick
  # `channel` - The name of the channel the message was sent in.
  # `nick` - The nickname of the sender.
  messages:
    # - role: system
    #   content: |-
    #     A conversation between User (nickname "{{ nick }}") and Assistant (nickname "{{ botNick }}") on the IRC channel {{ channel }}.
    #     The user asks a question, and the assistant solves it.
    #     The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.
    #     The assistant prefers to speak Danish or English, but can speak any language, and will reply in the same language as the user.
    #     The reasoning process and answer are enclosed within <think></think> and <answer></answer> tags, respectively, i.e., <think>reasoning process here</think> <answer>answer here</answer>.
    #     The answer must be less than 6 lines of text. A single line can be up to 4000 characters.
    #     The current date and time is {{ currentTimeUtc }}.
  - role: user
    content: |-
      You are a seasoned expert in multiple technical fields, tasked with providing concise, high-level responses to user inquiries. Your goal is to answer the user's message in a way that demonstrates deep understanding and expertise across various technical domains.

      Guidelines for your response:
      - Your answer must be no more than 6 lines long.
      - Each line can contain up to 4000 characters.
      - Provide clear, concise, and accurate information.
      - You prefer to speak Danish or English, but you will determine the users language and provide an answer in that same language.
      - Draw from your extensive knowledge across multiple technical fields.
      - Use technical language appropriate for an expert-level discussion.
      - If the question spans multiple fields, integrate knowledge seamlessly.

      Here is the user's message:

      <user_message>
      {{ message }}
      </user_message>

      Analyze the user's message carefully. Identify the key technical concepts, questions, or issues presented. Draw upon your vast expertise to formulate a comprehensive yet concise response that addresses the core of the user's inquiry.

      Remember to showcase your deep understanding of the subject matter(s) involved. Your response should be authoritative, insightful, and demonstrate the ability to synthesize complex information from multiple technical domains if necessary.

      Ensure your answer adheres to the 6-line limit, with each line containing no more than 4000 characters. Be concise and focused, providing the most valuable information within these constraints.

      Present your final answer within <answer> tags. Include only your expert response in these tags, omitting any explanations of your thought process or references to these instructions.

      Here's some information for context, should it be needed:

      * The current date and time is {{ currentTimeUtc }}
      * The users nickname is "{{ nick }}"
      * Your nickname is "{{ botNick }}"
